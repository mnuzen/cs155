{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "Authors: Fabian Boemer, Sid Murching, Suraj Nair, Alex Cui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2C:\n",
    "Fill in these functions to train your SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_U(Ui, Yij, Vj, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Ui multiplied by eta.\n",
    "    \"\"\"\n",
    "    t1 = reg * Ui\n",
    "    \n",
    "    Vj = np.squeeze(np.asarray(Vj))\n",
    "    Ui = np.squeeze(np.asarray(Ui))\n",
    "    \n",
    "    UT = np.dot(Vj,Ui)\n",
    "    t2 = Vj * (Yij - UT)\n",
    "    return eta*(t1 - t2)   \n",
    "\n",
    "def grad_V(Ui, Yij, Vj, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
    "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Vj multiplied by eta.\n",
    "    \"\"\"\n",
    "    t1 = reg * Vj\n",
    "    \n",
    "    Vj = np.squeeze(np.asarray(Vj))\n",
    "    Ui = np.squeeze(np.asarray(Ui))\n",
    "    \n",
    "    UT = np.dot(Vj,Ui)\n",
    "    t2 = Ui * (Yij - UT)\n",
    "    return eta*(t1 - t2)\n",
    "\n",
    "def get_err(U, V, Y, reg=0.0):\n",
    "    \"\"\"\n",
    "    Takes as input a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n",
    "    j is the index of a movie, and Y_ij is user i's rating of movie j and\n",
    "    user/movie matrices U and V.\n",
    "\n",
    "    Returns the mean regularized squared-error of predictions made by\n",
    "    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n",
    "    \"\"\"\n",
    "    totErr = 0\n",
    "    U_transpose = np.matrix(np.transpose(U))\n",
    "    rest = np.asarray(U_transpose * np.matrix(V))\n",
    "    #assert(rest.shape == Y.shape)\n",
    "    \n",
    "    for row in range(len(Y)):\n",
    "        for col in range(len(Y[0])):\n",
    "            if Y[row][col] > 0.1:\n",
    "                totErr += pow(Y[row][col] - rest[row][col],2)\n",
    "    return sqrt(totErr)\n",
    "\n",
    "def train_model(M, N, K, eta, reg, Y, eps=0.0001, max_epochs=300):\n",
    "    \"\"\"\n",
    "    Given a training data matrix Y containing rows (i, j, Y_ij)\n",
    "    where Y_ij is user i's rating on movie j, learns an\n",
    "    M x K matrix U and N x K matrix V such that rating Y_ij is approximated\n",
    "    by (UV^T)_ij.\n",
    "\n",
    "    Uses a learning rate of <eta> and regularization of <reg>. Stops after\n",
    "    <max_epochs> epochs, or once the magnitude of the decrease in regularized\n",
    "    MSE between epochs is smaller than a fraction <eps> of the decrease in\n",
    "    MSE after the first epoch.\n",
    "\n",
    "    Returns a tuple (U, V, err) consisting of U, V, and the unregularized MSE\n",
    "    of the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"M: \", M)\n",
    "    print(\"K: \", K)\n",
    "    \n",
    "    i = []\n",
    "    j = []\n",
    "    Y_ij = []\n",
    "    allLoss = []\n",
    "\n",
    "    for x in range(len(Y)):\n",
    "        i1, j1, y_ij1 = Y[x]\n",
    "        i.append(i1)\n",
    "        j.append(j1)\n",
    "        Y_ij.append(y_ij1)\n",
    "        #print(i1, \"/\", j1, \"/\", y_ij1)\n",
    "        \n",
    "    U = np.random.uniform(-.5,.5, size=(M, K))\n",
    "    V = np.random.uniform(-.5,.5, size=(N, K))\n",
    "        \n",
    "    for _ in range(max_epochs):\n",
    "        rp = random.randint(0, len(i))\n",
    "        rU = int(i[rp]-1)\n",
    "        rV = int(j[rp]-1)\n",
    "        \n",
    "        U[rU] += grad_U( U[rU], Y_ij[rp], V[rV], reg, eta)\n",
    "        V[rV] += grad_V( U[rU], Y_ij[rp], V[rV], reg, eta)\n",
    "        allLoss.append(get_err(U, V, Y))\n",
    "       \n",
    "    return (U, V, allLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D:\n",
    "Run the cell below to get your graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.loadtxt('./data/train.txt').astype(int)\n",
    "Y_test = np.loadtxt('./data/test.txt').astype(int)\n",
    "\n",
    "M = max(max(Y_train[:,0]), max(Y_test[:,0])).astype(int) # users\n",
    "N = max(max(Y_train[:,1]), max(Y_test[:,1])).astype(int) # movies\n",
    "print(\"Factorizing with \", M, \" users, \", N, \" movies.\")\n",
    "Ks = [10,20,30,50,100]\n",
    "\n",
    "reg = 0.0\n",
    "eta = 0.03 # learning rate\n",
    "E_in = []\n",
    "E_out = []\n",
    "\n",
    "# Use to compute Ein and Eout\n",
    "for K in Ks:\n",
    "    U,V, err = train_model(M, N, K, eta, reg, Y_train)\n",
    "    E_in.append(err)\n",
    "    E_out.append(get_err(U, V, Y_test))\n",
    "\n",
    "plt.plot(Ks, E_in, label='$E_{in}$')\n",
    "plt.plot(Ks, E_out, label='$E_{out}$')\n",
    "plt.title('Error vs. K')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.savefig('2d.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2E:\n",
    "Run the cell below to get your graphs. This might take a long time to run, but it should take less than 2 hours. I would encourage you to validate your 2C is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.loadtxt('./data/train.txt').astype(int)\n",
    "Y_test = np.loadtxt('./data/test.txt').astype(int)\n",
    "\n",
    "M = max(max(Y_train[:,0]), max(Y_test[:,0])).astype(int) # users\n",
    "N = max(max(Y_train[:,1]), max(Y_test[:,1])).astype(int) # movies\n",
    "Ks = [10,20,30,50,100]\n",
    "\n",
    "regs = [10**-4, 10**-3, 10**-2, 10**-1, 1]\n",
    "eta = 0.03 # learning rate\n",
    "E_ins = []\n",
    "E_outs = []\n",
    "\n",
    "# Use to compute Ein and Eout\n",
    "for reg in regs:\n",
    "    E_ins_for_lambda = []\n",
    "    E_outs_for_lambda = []\n",
    "\n",
    "    for k in Ks:\n",
    "        print(\"Training model with M = %s, N = %s, k = %s, eta = %s, reg = %s\"%(M, N, k, eta, reg))\n",
    "        U,V, e_in = train_model(M, N, k, eta, reg, Y_train)\n",
    "        E_ins_for_lambda.append(e_in)\n",
    "        eout = get_err(U, V, Y_test)\n",
    "        E_outs_for_lambda.append(eout)\n",
    "\n",
    "    E_ins.append(E_ins_for_lambda)\n",
    "    E_outs.append(E_outs_for_lambda)\n",
    "\n",
    "\n",
    "# Plot values of E_in across k for each value of lambda\n",
    "for i in range(len(regs)):\n",
    "    plt.plot(Ks, E_ins[i], label='$E_{in}, \\lambda=$'+str(regs[i]))\n",
    "plt.title('$E_{in}$ vs. K')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.savefig('2e_ein.png')\t\n",
    "plt.clf()\n",
    "\n",
    "# Plot values of E_out across k for each value of lambda\n",
    "for i in range(len(regs)):\n",
    "    plt.plot(Ks, E_outs[i], label='$E_{out}, \\lambda=$'+str(regs[i]))\n",
    "plt.title('$E_{out}$ vs. K')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\t\n",
    "plt.savefig('2e_eout.png')\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
