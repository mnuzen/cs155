{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "from HMM import supervised_HMM, unsupervised_HMM, HiddenMarkovModel\n",
    "import re # regular expression\n",
    "\n",
    "import keras.preprocessing.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_map(lines):\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in lines:\n",
    "        obs_elem = []\n",
    "\n",
    "        for word in line:\n",
    "            word = re.sub(r'[^\\w]', '', word).lower()\n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "\n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "\n",
    "        # Add the encoded sequence.\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_learning(lines, n_states, n_iters):\n",
    "    '''\n",
    "    n_iters: Number of iterations we should go through.\n",
    "    n_states: Number of hidden states our HMM should have.\n",
    "    '''\n",
    "    # Train the HMM.\n",
    "    obs, obs_map =  parse_map(lines)\n",
    "    flat_lines = [[item] for sublist in lines for item in sublist]\n",
    "    leHMM = unsupervised_HMM(obs, n_states, n_iters)\n",
    "    return leHMM, obs,obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_poems(files):\n",
    "    \n",
    "    lines = [] # 2d dictionary, each array is a split + cleaned line\n",
    "    words = {} # dictionary of a word, and its frequency\n",
    "    \n",
    "    for f in files:\n",
    "        file = open(f, 'r')\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if  len(line) < 10:\n",
    "                # Too short to be a valid line\n",
    "                continue\n",
    "            line = \"\".join(l for l in line if l not in string.punctuation)\n",
    "            line = line.lower()\n",
    "            line = line.split()\n",
    "\n",
    "            lines.append(line)\n",
    "\n",
    "            for word in line:\n",
    "                try:\n",
    "                    # add to frequency if the word is already in the dic\n",
    "                    words[word] += 1\n",
    "                except KeyError:\n",
    "                    # if not, add the word to the dic\n",
    "                    words[word] = 1\n",
    "    return lines, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_HMM(hmmmmmm, filename):\n",
    "    \n",
    "    with open(filename+\".txt\", \"w+\") as filept:\n",
    "        filept.write(str(hmmmmmm.L)+\"\\n\")\n",
    "        filept.write(str(hmmmmmm.D)+\"\\n\")\n",
    "        for i in hmmmmmm.A:\n",
    "            line = \"\"\n",
    "            for j in i:\n",
    "                line += str(j) + \",\"\n",
    "            filept.write(line[:len(line)-1]+\"\\n\")\n",
    "        for i in hmmmmmm.O:\n",
    "            line = \"\"\n",
    "            for j in i:\n",
    "                line += str(j) + \",\"\n",
    "            filept.write(line[:len(line)-1]+\"\\n\")\n",
    "        \n",
    "\n",
    "def read_HMM(filename):\n",
    "    with open(filename+\".txt\", \"r\") as filept:\n",
    "        L = int(filept.readline())\n",
    "        D = int(filept.readline())\n",
    "        O = []\n",
    "        A = []\n",
    "        for i in range(L):\n",
    "            line = [float(x) for x in filept.readline().split(\",\")]\n",
    "            A.append(line)\n",
    "        for j in range(L):\n",
    "            line = [float(x) for x in filept.readline().split(\",\")]\n",
    "            O.append(line)\n",
    "    return HiddenMarkovModel(A, O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merp 0\n",
      "merp 1\n",
      "merp 2\n",
      "merp 3\n",
      "merp 4\n",
      "merp 5\n",
      "merp 6\n",
      "merp 7\n",
      "merp 8\n",
      "merp 9\n",
      "merp 10\n",
      "merp 11\n",
      "merp 12\n",
      "merp 13\n",
      "merp 14\n",
      "merp 15\n",
      "merp 16\n",
      "merp 17\n",
      "merp 18\n",
      "merp 19\n",
      "merp 20\n",
      "merp 21\n",
      "merp 22\n",
      "merp 23\n",
      "merp 24\n",
      "merp 25\n",
      "merp 26\n",
      "merp 27\n",
      "merp 28\n",
      "merp 29\n",
      "merp 30\n",
      "merp 31\n",
      "merp 32\n",
      "merp 33\n",
      "merp 34\n",
      "merp 35\n",
      "merp 36\n",
      "merp 37\n",
      "merp 38\n",
      "merp 39\n"
     ]
    }
   ],
   "source": [
    "file = \"data/shakespeare.txt\"\n",
    "file2 = \"data/spenser.txt\"\n",
    "lines, words = load_poems([file, file2])\n",
    "HMM = unsupervised_learning(lines, 12, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stress(all_words):\n",
    "    stress = nltk.corpus.cmudict.dict()\n",
    "    stress_dict = {}\n",
    "    unclear = []\n",
    "\n",
    "\n",
    "    for word in all_words:\n",
    "        if word not in stress.keys():\n",
    "            unclear.append(word)\n",
    "        else:\n",
    "            stress_dict[word] = stress[word]\n",
    "\n",
    "    for word in stress_dict.keys():\n",
    "        phoneme = stress_dict[word][0]\n",
    "        syls = []\n",
    "\n",
    "        for phon in phoneme:\n",
    "            if '0' in phon:\n",
    "                syls.append(0)\n",
    "            elif '1' in phon:\n",
    "                syls.append(1)\n",
    "\n",
    "        stress_dict[word] = syls\n",
    "\n",
    "    return stress_dict, unclear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = list(words.keys())\n",
    "# for the stress, just use the first thing from the array\n",
    "stress_dict, unclear = load_stress(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_map_reverser(obs_map):\n",
    "    obs_map_r = {}\n",
    "\n",
    "    for key in obs_map:\n",
    "        obs_map_r[obs_map[key]] = key\n",
    "\n",
    "    return obs_map_r\n",
    "\n",
    "# get syllable info from syllable_dictionary.txt\n",
    "def load_syllables(filename):\n",
    "    file = open(filename, 'r')\n",
    "    syllable = {}\n",
    "    for line in file:\n",
    "        line = line.split()\n",
    "        #print(line)\n",
    "        word = line[0]\n",
    "        rest = line[1: len(line)]\n",
    "\n",
    "        syllable[word] = rest\n",
    "    return syllable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare are too mine on tongue and love thee we\n",
      "The gilded thee in alike so a name\n",
      "There may as smother the remedy joy\n",
      "Though wait with her by love favour to for\n",
      "Costly didst another clouds depart true\n",
      "Thy love supposed am like me writ thy a\n",
      "Me from shall he best like that due not which\n",
      "And then travels spoils was out solemn which\n",
      "And from a name grievances his heart show\n",
      "May sits in the lack is countenance thy\n",
      "Be so in to up now this my love fly\n",
      "Never was needs love for sang thereof blood\n",
      "As any earth her with full arts so proud\n",
      "O goodly do grace such from men burn thus\n"
     ]
    }
   ],
   "source": [
    "obs, obs_map = parse_map(lines)\n",
    "obs_map_r =  obs_map_reverser(obs_map)\n",
    "filename = \"data/Syllable_dictionary.txt\"\n",
    "\n",
    "syllable = load_syllables(filename)\n",
    "for i in range(14): # each poem is 14 lines long\n",
    "        emission = HMM[0].generate_emission_syllables_correct(10, obs_map_r, syllable) # each line is 10 syllables long\n",
    "        sentence = [obs_map_r[i] for i in emission[0]]\n",
    "\n",
    "        print(' '.join(sentence).capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
